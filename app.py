import streamlit as st
import requests
import pandas as pd
import matplotlib.pyplot as plt
import time
import pytesseract
from PIL import Image, ImageEnhance, ImageFilter
from openai import OpenAI # Importa o cliente OpenAI
import io
import re
import base64

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(
    page_title="BrainX Neural Architect",
    page_icon="üß†",
    layout="centered", 
    initial_sidebar_state="expanded"
)

# --- INICIALIZA√á√ÉO DO ESTADO DE SESS√ÉO (MEM√ìRIA) ---
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'resolution_base' not in st.session_state:
    st.session_state.resolution_base = ""

# --- ESTILIZA√á√ÉO & CABE√áALHO ---
st.markdown("""
<style>
    /* ... (CSS mantido) ... */
    .main {background-color: #f8f9fa;}
    h1 {color: #0F172A; font-size: 2.2rem;}
    .stButton>button {
        background-color: #0F172A;
        color: white;
        border-radius: 8px;
        height: 3.5em;
        width: 100%;
        font-weight: bold;
        border: 1px solid #1E293B;
        margin-top: 10px;
    }
    .stFileUploader {border-radius: 10px; border: 2px dashed #0F172A; padding: 15px;}
    .block-container {padding-top: 2rem; padding-bottom: 2rem;}
</style>
""", unsafe_allow_html=True)

st.image("https://img.icons8.com/color/96/000000/brain--v1.png", width=70)
st.title("BrainX Neural ENEM Architect")
st.markdown("### N√∫cleo de Intelig√™ncia Artificial | **Powered by XTRI**")
st.markdown("---")

# --- SIDEBAR (CONFIGURA√á√ÉO) ---
st.sidebar.header("‚öôÔ∏è Configura√ß√£o H√≠brida")

# Chave 1: Maritaca (Sabi√°-3)
maritaca_key = st.sidebar.text_input("Maritaca KEY (Sabi√°-3):", type="password", 
    value=st.secrets.get("api_gpt_assistente") or st.secrets.get("MARITACA_KEY"))

# Chave 2: OpenAI (Vis√£o)
openai_key = st.sidebar.text_input("OpenAI KEY (Vis√£o GPT-4o):", type="password", 
    value=st.secrets.get("OPENAI_API_KEY"))

st.sidebar.markdown("---")
modo = st.sidebar.radio("Ferramenta:", 
    ["üì∏ Resolver Quest√£o (OCR)", "üß≠ Rota de Estudos por TRI"]
)
st.sidebar.info("v4.0 Stable | Powered by XTRI")

# --- FUN√á√ïES CORE ---

def corrigir_latex_visual(texto):
    if not texto: return ""
    texto = re.sub(r'\\\[\s*(.*?)\s*\\\]', r'$$\1$$', texto) # Padr√£o acad√™mico
    texto = re.sub(r'\\\(\s*(.*?)\s*\\\)', r'$\1$', texto) # Padr√£o acad√™mico inline
    texto = re.sub(r'\[\s*(.*?)\s*\]', r'$$\1$$', texto) # Padr√£o brackets que o modelo usa
    return texto

@st.cache_data(show_spinner=False)
def chamar_brainx(prompt, api_key_maritaca):
    # ... (API call logic, mantida) ...
    if not api_key_maritaca: return "‚ö†Ô∏è ERRO: Chave Maritaca ausente."
    
    headers = {"Authorization": f"Bearer {api_key_maritaca}", "Content-Type": "application/json"}
    data = {
        "model": "sabia-3", 
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.0,
        "max_tokens": 3000
    }
    
    try:
        response = requests.post("https://chat.maritaca.ai/api/chat/completions", headers=headers, json=data)
        if response.status_code == 200:
            return response.json()['choices'][0]['message']['content']
        return f"Erro BrainX API ({response.status_code}): {response.text}"
    except Exception as e:
        return f"Erro Conex√£o: {str(e)}"

# OCR e Vis√£o (GPT-4o)
def vision_ocr_and_description(base64_image, api_key):
    # ... (Vision call logic, mantida) ...
    try:
        client = OpenAI(api_key=api_key)
        prompt_vision = "Analise esta imagem (screenshot de uma quest√£o do ENEM). Extraia o enunciado completo, o comando final e TODAS as alternativas, mantendo a formata√ß√£o e ordem exatas (A, B, C, D, E). N√£o adicione nenhum coment√°rio ou texto extra. Seja estritamente um leitor de OCR de alta qualidade."

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": [{"type": "text", "text": prompt_vision}, {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}]}],
            max_tokens=1024,
            temperature=0.0
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"ERRO VISION API: {e}"

def encode_image(image_file):
    return base64.b64encode(image_file.getvalue()).decode('utf-8')

# FUN√á√ÉO CENTRAL DE INTERA√á√ÉO (Para uso na caixa de chat)
def handle_follow_up(user_input):
    # Constr√≥i o contexto da conversa: Resolu√ß√£o anterior + Nova Pergunta
    contexto_completo = f"CONTE√öDO BASE (RESOLU√á√ÉO ANTERIOR): {st.session_state.resolution_base}\n\nD√öVIDA DO ALUNO: {user_input}"
    
    response = chamar_brainx(contexto_completo, maritaca_key)
    
    # Atualiza o hist√≥rico
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    st.session_state.chat_history.append({"role": "assistant", "content": response})

    st.rerun() # <<< CORRE√á√ÉO CR√çTICA AQUI: Usando st.rerun()


# ==============================================================================
# M√ìDULO 1: RESOLVER QUEST√ÉO (O CHAT √â IMPLEMENTADO)
# ==============================================================================
if modo == "üì∏ Resolver Quest√£o (OCR)":
    st.header("üéì Resolu√ß√£o S√™nior (BrainX)")

    # Bot√£o de Reset
    if st.button("Limpar Sess√£o e Come√ßar Novo"):
        st.session_state.resolution_base = ""
        st.session_state.chat_history = []
        st.rerun() # <<< CORRE√á√ÉO CR√çTICA AQUI

    # --- FLUXO INICIAL (Aparece se n√£o houver resolu√ß√£o) ---
    if not st.session_state.resolution_base:
        st.markdown("**1. Upload do Print:**")
        arquivo = st.file_uploader("Subir Print da Tela (Imagem):", type=["png", "jpg", "jpeg"])
        texto_extraido = ""
        
        if arquivo:
            if not openai_key:
                st.error("‚ùå Por favor, configure a chave OpenAI para leitura da imagem (GPT-4o).")
            else:
                with st.spinner("üëÅÔ∏è GPT-4o lendo e corrigindo texto..."):
                    texto_extraido = vision_ocr_and_description(encode_image(arquivo), openai_key)
                    if "ERRO" in texto_extraido: st.error(texto_extraido)
                    else: st.success("Texto lido e corrigido!")
                    
        st.markdown("**2. Enunciado:**")
        input_final = st.text_area("...", value=texto_extraido if texto_extraido else "", height=250, placeholder="Cole ou edite a quest√£o aqui...")

        if st.button("Gerar Resolu√ß√£o Base"):
            if not input_final: st.warning("‚ö†Ô∏è Cole a quest√£o primeiro.")
            else:
                prompt_inicial = f"[PROTOCOLO DE 7 PASSOS] RESOLVA A QUEST√ÉO:\n{input_final}\n\nRESPOSTA FINAL OBRIGAT√ìRIA: **GABARITO: [Letra]**"
                with st.spinner("üß† Sabi√°-3 gerando a resolu√ß√£o base..."):
                    resposta_base = chamar_brainx(prompt_inicial, maritaca_key)
                
                # Armazena a resolu√ß√£o base e reinicia o fluxo para mostrar o chat
                st.session_state.resolution_base = resposta_base
                st.session_state.chat_history = [{"role": "assistant", "content": resposta_base}]
                st.rerun() # <<< CORRE√á√ÉO CR√çTICA AQUI

    # --- CHAT DE TUTORIA INTERATIVA (Aparece ap√≥s a primeira resolu√ß√£o) ---
    else:
        st.subheader("üí¨ Tutoria Interativa BrainX")
        st.info("Resolu√ß√£o Base Conclu√≠da. Pergunte sobre os passos ou conceitos!")
        
        # 1. Exibir Resolu√ß√£o Base
        with st.expander("Ver Resolu√ß√£o Completa", expanded=False):
            st.markdown(corrigir_latex_visual(st.session_state.resolution_base))
            
        # 2. Exibir Hist√≥rico do Chat
        for message in st.session_state.chat_history:
            if message["role"] == "assistant":
                st.info(corrigir_latex_visual(message["content"]))
            elif message["role"] == "user":
                st.markdown(f"**Voc√™:** {message['content']}")
                
        # 3. Caixa de Input para o Aluno
        user_input = st.text_input("Sua D√∫vida sobre a resolu√ß√£o:")
        
        if user_input and st.session_state.resolution_base:
            handle_follow_up(user_input)
            # O handle_follow_up j√° chama st.rerun()

# [O restante dos m√≥dulos (ROTA TRI) ficam inalterados, pois n√£o precisam de chat]
